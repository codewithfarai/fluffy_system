---
- name: Create monitoring directories on all nodes
  hosts: all
  become: yes
  tasks:
    - name: Create monitoring directories
      file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
      loop:
        - /opt/docker/stacks/monitoring
        - /opt/docker/stacks/monitoring/prometheus/data
        - /opt/docker/stacks/monitoring/prometheus/config
        - /opt/docker/stacks/monitoring/grafana/data
        - /opt/docker/stacks/monitoring/grafana/provisioning/datasources
        - /opt/docker/stacks/monitoring/grafana/provisioning/dashboards
        - /opt/docker/stacks/monitoring/alertmanager/data
        - /opt/docker/stacks/monitoring/alertmanager/config
        - /opt/docker/stacks/monitoring/loki/data
        - /opt/docker/stacks/monitoring/loki/config
        - /opt/docker/stacks/monitoring/promtail/config

- name: Deploy Monitoring Stack (Prometheus, Grafana, Alertmanager)
  hosts: managers[0]
  become: yes
  vars:
    monitoring_stack_name: monitoring
    prometheus_version: "v2.47.0"
    grafana_version: "10.1.0"
    alertmanager_version: "v0.26.0"
    node_exporter_version: "v1.6.1"
    cadvisor_version: "v0.47.0"
    loki_version: "2.9.0"
    promtail_version: "2.9.0"
    grafana_domain: "grafana.{{ base_domain }}"
    prometheus_domain: "prometheus.{{ base_domain }}"
    alertmanager_domain: "alertmanager.{{ base_domain }}"
    loki_domain: "loki.{{ base_domain }}"
    
  tasks:
    - name: Check if Grafana password file exists
      stat:
        path: /opt/docker/stacks/monitoring/grafana_password.txt
      register: grafana_password_file_stat

    - name: Generate Grafana admin password
      shell: echo $(openssl rand -base64 32)
      register: grafana_password_generated
      when: not grafana_password_file_stat.stat.exists
      run_once: true

    - name: Save generated password to file
      copy:
        content: "{{ grafana_password_generated.stdout }}"
        dest: /opt/docker/stacks/monitoring/grafana_password.txt
        mode: '0600'
      when: not grafana_password_file_stat.stat.exists

    - name: Read existing password from file
      slurp:
        src: /opt/docker/stacks/monitoring/grafana_password.txt
      register: existing_grafana_password
      when: grafana_password_file_stat.stat.exists

    - name: Set password fact
      set_fact:
        grafana_password: "{{ grafana_password_generated.stdout if not grafana_password_file_stat.stat.exists else (existing_grafana_password.content | b64decode | trim) }}"
      when: inventory_hostname == groups['managers'][0]

    - name: Generate Prometheus basic auth password
      shell: echo $(openssl rand -base64 32)
      register: prometheus_password_generated
      run_once: true

    - name: Generate Prometheus password hash
      shell: echo -n "{{ prometheus_password_generated.stdout }}" | openssl passwd -apr1 -stdin
      register: prometheus_password_hash
      run_once: true

    - name: Create Prometheus web configuration
      copy:
        content: |
          basic_auth_users:
            admin: {{ prometheus_password_hash.stdout }}
        dest: /opt/docker/stacks/monitoring/prometheus/config/web.yml
        mode: '0644'


    - name: Create Prometheus configuration
      copy:
        content: |
          global:
            scrape_interval: 15s
            evaluation_interval: 15s
            external_labels:
              cluster: 'docker-swarm'
              replica: 'prometheus'

          rule_files:
            - "/etc/prometheus/rules/*.yml"

          alerting:
            alertmanagers:
              - static_configs:
                  - targets:
                    - alertmanager:9093

          scrape_configs:
            - job_name: 'prometheus'
              static_configs:
                - targets: ['localhost:9090']

            - job_name: 'node-exporter'
              dns_sd_configs:
                - names:
                  - 'tasks.node-exporter'
                  type: 'A'
                  port: 9100

            - job_name: 'cadvisor'
              dns_sd_configs:
                - names:
                  - 'tasks.cadvisor'
                  type: 'A'
                  port: 8080

            - job_name: 'docker-swarm-managers'
              static_configs:
                - targets:
                  - 'manager-1:9323'
                  - 'manager-2:9323'
                  - 'manager-3:9323'

            - job_name: 'traefik'
              static_configs:
                - targets: ['traefik_traefik:8082']

            - job_name: 'alertmanager'
              static_configs:
                - targets: ['alertmanager:9093']

            - job_name: 'grafana'
              static_configs:
                - targets: ['grafana:3000']
        dest: /opt/docker/stacks/monitoring/prometheus/config/prometheus.yml
        mode: '0644'

    - name: Create Prometheus alerting rules
      copy:
        content: |
          groups:
          - name: docker-swarm
            rules:
            - alert: ServiceDown
              expr: up == 0
              for: 30s
              labels:
                severity: critical
              annotations:
                summary: "Service {{ "{{" }} $labels.instance {{ "}}" }} is down"
                description: "{{ "{{" }} $labels.instance {{ "}}" }} of job {{ "{{" }} $labels.job {{ "}}" }} has been down for more than 30 seconds."

            - alert: HighMemoryUsage
              expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.85
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: "High memory usage on {{ "{{" }} $labels.instance {{ "}}" }}"
                description: "Memory usage is above 85% on {{ "{{" }} $labels.instance {{ "}}" }}"

            - alert: HighCPUUsage
              expr: 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: "High CPU usage on {{ "{{" }} $labels.instance {{ "}}" }}"
                description: "CPU usage is above 80% on {{ "{{" }} $labels.instance {{ "}}" }}"

            - alert: DiskSpaceLow
              expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) < 0.1
              for: 1m
              labels:
                severity: critical
              annotations:
                summary: "Disk space low on {{ "{{" }} $labels.instance {{ "}}" }}"
                description: "Disk space is below 10% on {{ "{{" }} $labels.instance {{ "}}" }}"

            - alert: ContainerKilled
              expr: increase(container_tasks_state{state="dead"}[1m]) > 0
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: "Container killed on {{ "{{" }} $labels.instance {{ "}}" }}"
                description: "A container was killed on {{ "{{" }} $labels.instance {{ "}}" }}"

          - name: security-monitoring
            rules:
            - alert: UnauthorizedAPIAccess
              expr: increase(prometheus_http_requests_total{code=~"4.."}[5m]) > 10
              for: 1m
              labels:
                severity: warning
              annotations:
                summary: "Unusual number of 4xx responses detected"
                description: "{{ "{{" }} $value {{ "}}" }} 4xx HTTP responses detected in the last 5 minutes on {{ "{{" }} $labels.instance {{ "}}" }}"

            - alert: AdminAPIAccess
              expr: increase(prometheus_http_requests_total{handler="/api/v1/admin/tsdb"}[1m]) > 0
              for: 0m
              labels:
                severity: critical
              annotations:
                summary: "Admin API accessed"
                description: "Prometheus admin API was accessed on {{ "{{" }} $labels.instance {{ "}}" }}"

            - alert: HighLoginFailures
              expr: increase(grafana_api_login_post_total{status="error"}[5m]) > 5
              for: 1m
              labels:
                severity: warning
              annotations:
                summary: "High number of Grafana login failures"
                description: "{{ "{{" }} $value {{ "}}" }} login failures detected in Grafana in the last 5 minutes"

            - alert: ServiceRestart
              expr: increase(node_systemd_unit_state{state="active"}[5m]) > 0
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: "Service restart detected"
                description: "Service {{ "{{" }} $labels.name {{ "}}" }} was restarted on {{ "{{" }} $labels.instance {{ "}}" }}"

            - alert: DiskSpaceFillingFast
              expr: predict_linear(node_filesystem_avail_bytes[1h], 4*3600) < 0
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: "Disk space filling fast"
                description: "Disk on {{ "{{" }} $labels.instance {{ "}}" }} will be full in approximately 4 hours"

            - alert: HostNetworkInterfaceDown
              expr: node_network_up == 0
              for: 1m
              labels:
                severity: warning
              annotations:
                summary: "Network interface down"
                description: "Network interface {{ "{{" }} $labels.device {{ "}}" }} is down on {{ "{{" }} $labels.instance {{ "}}" }}"
        dest: /opt/docker/stacks/monitoring/prometheus/config/rules.yml
        mode: '0644'

    - name: Generate Alertmanager basic auth password
      shell: echo $(openssl rand -base64 32)
      register: alertmanager_password_generated
      run_once: true

    - name: Generate Alertmanager password hash
      shell: echo -n "{{ alertmanager_password_generated.stdout }}" | openssl passwd -apr1 -stdin
      register: alertmanager_password_hash
      run_once: true

    - name: Create Alertmanager web configuration
      copy:
        content: |
          basic_auth_users:
            admin: {{ alertmanager_password_hash.stdout }}
        dest: /opt/docker/stacks/monitoring/alertmanager/config/web.yml
        mode: '0644'

    - name: Generate Loki basic auth password
      shell: echo $(openssl rand -base64 32)
      register: loki_password_generated
      run_once: true

    - name: Generate Loki password hash
      shell: echo -n "{{ loki_password_generated.stdout }}" | openssl passwd -apr1 -stdin
      register: loki_password_hash
      run_once: true


    - name: Create Alertmanager configuration
      copy:
        content: |
          global:
            smtp_smarthost: '{{ smtp_server | default("localhost:587") }}'
            smtp_from: '{{ alert_from_email | default("alertmanager@" + base_domain) }}'

          route:
            group_by: ['alertname']
            group_wait: 10s
            group_interval: 10s
            repeat_interval: 1h
            receiver: 'email-alerts'

          receivers:
          - name: 'email-alerts'
            email_configs:
            - to: '{{ alert_to_email | default("admin@" + base_domain) }}'
              subject: 'Docker Swarm Alert: {{ "{{" }} .GroupLabels.alertname {{ "}}" }}'
              body: |
                {{ "{{" }} range .Alerts {{ "}}" }}
                Alert: {{ "{{" }} .Annotations.summary {{ "}}" }}
                Description: {{ "{{" }} .Annotations.description {{ "}}" }}
                Status: {{ "{{" }} .Status {{ "}}" }}
                Severity: {{ "{{" }} .Labels.severity {{ "}}" }}
                {{ "{{" }} end {{ "}}" }}

          inhibit_rules:
            - source_match:
                severity: 'critical'
              target_match:
                severity: 'warning'
              equal: ['alertname', 'dev', 'instance']
        dest: /opt/docker/stacks/monitoring/alertmanager/config/alertmanager.yml
        mode: '0644'

    - name: Create Grafana datasource configuration
      copy:
        content: |
          apiVersion: 1
          datasources:
            - name: Prometheus
              type: prometheus
              access: proxy
              url: http://prometheus:9090
              isDefault: true
              editable: true
              basicAuth: true
              basicAuthUser: admin
              secureJsonData:
                basicAuthPassword: {{ prometheus_password_generated.stdout }}
            
            - name: Loki
              type: loki
              access: proxy
              url: http://loki:3100
              editable: true
              basicAuth: true
              basicAuthUser: admin
              jsonData:
                maxLines: 1000
                httpHeaderName1: 'X-Scope-OrgID'
                httpHeaderValue1: 'tenant1'
              secureJsonData:
                basicAuthPassword: {{ loki_password_generated.stdout }}
        dest: /opt/docker/stacks/monitoring/grafana/provisioning/datasources/prometheus.yml
        mode: '0644'

    - name: Create Grafana dashboard provisioning
      copy:
        content: |
          apiVersion: 1
          providers:
            - name: 'Docker Swarm'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              updateIntervalSeconds: 10
              allowUiUpdates: true
              options:
                path: /etc/grafana/provisioning/dashboards
        dest: /opt/docker/stacks/monitoring/grafana/provisioning/dashboards/dashboard.yml
        mode: '0644'

    - name: Create Loki configuration
      copy:
        content: |
          auth_enabled: true

          server:
            http_listen_port: 3100
            grpc_listen_port: 9096
            http_server_read_timeout: 30s
            http_server_write_timeout: 30s

          multitenancy_enabled: true

          common:
            instance_addr: 127.0.0.1
            path_prefix: /loki
            storage:
              filesystem:
                chunks_directory: /loki/chunks
                rules_directory: /loki/rules
            replication_factor: 1
            ring:
              kvstore:
                store: inmemory

          query_range:
            results_cache:
              cache:
                embedded_cache:
                  enabled: true
                  max_size_mb: 100

          schema_config:
            configs:
              - from: 2020-10-24
                store: boltdb-shipper
                object_store: filesystem
                schema: v11
                index:
                  prefix: index_
                  period: 24h

          ruler:
            alertmanager_url: http://alertmanager:9093

          limits_config:
            enforce_metric_name: false
            reject_old_samples: true
            reject_old_samples_max_age: 168h
            max_cache_freshness_per_query: 10m
            split_queries_by_interval: 15m
            max_query_parallelism: 32

          frontend:
            max_outstanding_per_tenant: 2048
            compress_responses: true

          query_scheduler:
            max_outstanding_requests_per_tenant: 2048
        dest: /opt/docker/stacks/monitoring/loki/config/loki.yml
        mode: '0644'

    - name: Create Promtail configuration
      copy:
        content: |
          server:
            http_listen_port: 9080
            grpc_listen_port: 0

          positions:
            filename: /tmp/positions.yaml

          clients:
            - url: http://loki:3100/loki/api/v1/push
              tenant_id: tenant1
              basic_auth:
                username: admin
                password: {{ loki_password_generated.stdout }}

          scrape_configs:
            - job_name: containers
              static_configs:
                - targets:
                    - localhost
                  labels:
                    job: containerlogs
                    __path__: /var/lib/docker/containers/*/*.log

              pipeline_stages:
                - json:
                    expressions:
                      output: log
                      stream: stream
                      attrs:
                - json:
                    expressions:
                      tag:
                    source: attrs
                - regex:
                    expression: (?P<container_name>(?:[^|]*/){2}(?P<container_name_only>[^.-]+))
                    source: tag
                - timestamp:
                    format: RFC3339Nano
                    source: time
                - labels:
                    stream:
                    container_name:
                    container_name_only:
                - output:
                    source: output

            - job_name: syslog
              static_configs:
                - targets:
                    - localhost
                  labels:
                    job: syslog
                    __path__: /var/log/syslog

            - job_name: docker
              static_configs:
                - targets:
                    - localhost
                  labels:
                    job: docker
                    __path__: /var/log/docker.log
        dest: /opt/docker/stacks/monitoring/promtail/config/promtail.yml
        mode: '0644'

    - name: Create monitoring stack file
      copy:
        content: |
          version: '3.8'
          
          services:
            prometheus:
              image: prom/prometheus:{{ prometheus_version }}
              command:
                - '--config.file=/etc/prometheus/prometheus.yml'
                - '--storage.tsdb.path=/prometheus'
                - '--storage.tsdb.retention.time=15d'
                - '--storage.tsdb.retention.size=5GB'
                - '--web.console.libraries=/etc/prometheus/console_libraries'
                - '--web.console.templates=/etc/prometheus/consoles'
                - '--web.config.file=/etc/prometheus/web.yml'
              volumes:
                - prometheus-data:/prometheus
                - prometheus-config:/etc/prometheus:ro
              networks:
                - monitoring-network
                - traefik-public
              deploy:
                mode: replicated
                replicas: 1
                placement:
                  constraints:
                    - node.role == manager
                resources:
                  limits:
                    memory: 2G
                  reservations:
                    memory: 1G
                update_config:
                  failure_action: rollback
                  parallelism: 1
                  delay: 10s
                restart_policy:
                  condition: on-failure
                  delay: 5s
                  max_attempts: 3
                labels:
                  - traefik.enable=true
                  - traefik.docker.network=traefik-public
                  - traefik.http.routers.prometheus.rule=Host(`{{ prometheus_domain }}`)
                  - traefik.http.routers.prometheus.entrypoints=websecure
                  - traefik.http.routers.prometheus.tls.certresolver=letsencrypt
                  - traefik.http.routers.prometheus.middlewares=security-headers,monitoring-rate-limit
                  - traefik.http.services.prometheus.loadbalancer.server.port=9090

            grafana:
              image: grafana/grafana:{{ grafana_version }}
              environment:
                GF_SECURITY_ADMIN_PASSWORD: {{ grafana_password }}
                GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource
                GF_PATHS_PROVISIONING: /etc/grafana/provisioning
                GF_SECURITY_COOKIE_SECURE: "true"
                GF_SECURITY_COOKIE_SAMESITE: "strict"
                GF_SECURITY_CONTENT_TYPE_PROTECTION: "true"
                GF_SECURITY_X_CONTENT_TYPE_OPTIONS: "nosniff"
                GF_SECURITY_X_XSS_PROTECTION: "true"
                GF_USERS_ALLOW_SIGN_UP: "false"
                GF_USERS_ALLOW_ORG_CREATE: "false"
                GF_LOG_MODE: "console file"
                GF_LOG_LEVEL: "info"
                GF_AUTH_DISABLE_LOGIN_FORM: "false"
                GF_SECURITY_DISABLE_GRAVATAR: "true"
              volumes:
                - grafana-data:/var/lib/grafana
                - grafana-provisioning:/etc/grafana/provisioning:ro
              networks:
                - monitoring-network
                - traefik-public
              deploy:
                mode: replicated
                replicas: 1
                placement:
                  constraints:
                    - node.role == worker
                resources:
                  limits:
                    memory: 1G
                  reservations:
                    memory: 512M
                update_config:
                  failure_action: rollback
                  parallelism: 1
                  delay: 10s
                restart_policy:
                  condition: on-failure
                  delay: 5s
                  max_attempts: 3
                labels:
                  - traefik.enable=true
                  - traefik.docker.network=traefik-public
                  - traefik.http.routers.grafana.rule=Host(`{{ grafana_domain }}`)
                  - traefik.http.routers.grafana.entrypoints=websecure
                  - traefik.http.routers.grafana.tls.certresolver=letsencrypt
                  - traefik.http.routers.grafana.middlewares=security-headers,monitoring-rate-limit
                  - traefik.http.services.grafana.loadbalancer.server.port=3000

            alertmanager:
              image: prom/alertmanager:{{ alertmanager_version }}
              command:
                - '--config.file=/etc/alertmanager/alertmanager.yml'
                - '--storage.path=/alertmanager'
                - '--web.config.file=/etc/alertmanager/web.yml'
              volumes:
                - alertmanager-data:/alertmanager
                - alertmanager-config:/etc/alertmanager:ro
              networks:
                - monitoring-network
                - traefik-public
              deploy:
                mode: replicated
                replicas: 1
                placement:
                  constraints:
                    - node.role == manager
                resources:
                  limits:
                    memory: 512M
                  reservations:
                    memory: 256M
                update_config:
                  failure_action: rollback
                  parallelism: 1
                  delay: 10s
                restart_policy:
                  condition: on-failure
                  delay: 5s
                  max_attempts: 3
                labels:
                  - traefik.enable=true
                  - traefik.docker.network=traefik-public
                  - traefik.http.routers.alertmanager.rule=Host(`{{ alertmanager_domain }}`)
                  - traefik.http.routers.alertmanager.entrypoints=websecure
                  - traefik.http.routers.alertmanager.tls.certresolver=letsencrypt
                  - traefik.http.routers.alertmanager.middlewares=security-headers,monitoring-rate-limit
                  - traefik.http.services.alertmanager.loadbalancer.server.port=9093

            node-exporter:
              image: prom/node-exporter:{{ node_exporter_version }}
              command:
                - '--path.rootfs=/host'
                - '--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)'
              volumes:
                - /:/host:ro,rslave
              networks:
                - monitoring-network
              deploy:
                mode: global
                resources:
                  limits:
                    memory: 128M
                  reservations:
                    memory: 64M

            cadvisor:
              image: gcr.io/cadvisor/cadvisor:{{ cadvisor_version }}
              command:
                - '--docker_only=true'
                - '--housekeeping_interval=30s'
                - '--disable_metrics=percpu,sched,tcp,udp,disk,diskIO,accelerator,hugetlb,referenced_memory,cpu_topology,resctrl'
              volumes:
                - /:/rootfs:ro
                - /var/run:/var/run:ro
                - /sys:/sys:ro
                - /var/lib/docker/:/var/lib/docker:ro
                - /dev/disk/:/dev/disk:ro
              networks:
                - monitoring-network
              deploy:
                mode: global
                resources:
                  limits:
                    memory: 256M
                  reservations:
                    memory: 128M

            loki:
              image: grafana/loki:{{ loki_version }}
              command: -config.file=/etc/loki/loki.yml
              volumes:
                - loki-data:/loki
                - loki-config:/etc/loki:ro
              networks:
                - monitoring-network
                - traefik-public
              deploy:
                mode: replicated
                replicas: 1
                placement:
                  constraints:
                    - node.role == worker
                resources:
                  limits:
                    memory: 1G
                  reservations:
                    memory: 512M
                update_config:
                  failure_action: rollback
                restart_policy:
                  condition: on-failure
                labels:
                  - traefik.enable=true
                  - traefik.docker.network=traefik-public
                  - traefik.http.routers.loki.rule=Host(`{{ loki_domain }}`)
                  - traefik.http.routers.loki.entrypoints=websecure
                  - traefik.http.routers.loki.tls.certresolver=letsencrypt
                  - traefik.http.routers.loki.middlewares=security-headers,monitoring-rate-limit,loki-auth
                  - traefik.http.middlewares.loki-auth.basicauth.users=admin:{{ loki_password_hash.stdout }}
                  - traefik.http.services.loki.loadbalancer.server.port=3100

            promtail:
              image: grafana/promtail:{{ promtail_version }}
              command: -config.file=/etc/promtail/promtail.yml
              volumes:
                - /var/log:/var/log:ro
                - /var/lib/docker/containers:/var/lib/docker/containers:ro
                - promtail-config:/etc/promtail:ro
              networks:
                - monitoring-network
              deploy:
                mode: global
                resources:
                  limits:
                    memory: 128M
                  reservations:
                    memory: 64M
                update_config:
                  failure_action: rollback
                restart_policy:
                  condition: on-failure

          volumes:
            prometheus-data:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /opt/docker/stacks/monitoring/prometheus/data
            prometheus-config:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /opt/docker/stacks/monitoring/prometheus/config
            grafana-data:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /opt/docker/stacks/monitoring/grafana/data
            grafana-provisioning:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /opt/docker/stacks/monitoring/grafana/provisioning
            alertmanager-data:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /opt/docker/stacks/monitoring/alertmanager/data
            alertmanager-config:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /opt/docker/stacks/monitoring/alertmanager/config
            loki-data:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /opt/docker/stacks/monitoring/loki/data
            loki-config:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /opt/docker/stacks/monitoring/loki/config
            promtail-config:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /opt/docker/stacks/monitoring/promtail/config

          networks:
            monitoring-network:
              driver: overlay
              attachable: true
            traefik-public:
              external: true
        dest: /opt/docker/stacks/monitoring/docker-compose.yml
        mode: '0644'

    - name: Deploy monitoring stack
      shell: docker stack deploy -c /opt/docker/stacks/monitoring/docker-compose.yml {{ monitoring_stack_name }}
      register: monitoring_deploy_result

    - name: Wait for Prometheus service to be ready
      shell: docker service ls --filter name={{ monitoring_stack_name }}_prometheus --format "{{ "{{" }}.Replicas{{ "}}" }}"
      register: prometheus_replicas
      until: prometheus_replicas.stdout.find("/") != -1 and prometheus_replicas.stdout.split("/")[0] == prometheus_replicas.stdout.split("/")[1]
      retries: 30
      delay: 10

    - name: Wait for Grafana service to be ready
      shell: docker service ls --filter name={{ monitoring_stack_name }}_grafana --format "{{ "{{" }}.Replicas{{ "}}" }}"
      register: grafana_replicas
      until: grafana_replicas.stdout.find("/") != -1 and grafana_replicas.stdout.split("/")[0] == grafana_replicas.stdout.split("/")[1]
      retries: 30
      delay: 10

    - name: Display monitoring deployment information
      debug:
        msg:
          - "Monitoring stack deployed successfully!"
          - "Grafana URL: https://{{ grafana_domain }}"
          - "Grafana Username: admin"
          - "Grafana Password: {{ grafana_password }}"
          - "Prometheus URL: https://{{ prometheus_domain }}"
          - "Prometheus Username: admin"
          - "Prometheus Password: {{ prometheus_password_generated.stdout }}"
          - "Alertmanager URL: https://{{ alertmanager_domain }}"
          - "Alertmanager Username: admin"
          - "Alertmanager Password: {{ alertmanager_password_generated.stdout }}"
          - "Loki URL: https://{{ loki_domain }}"
          - "Loki Username: admin"
          - "Loki Password: {{ loki_password_generated.stdout }}"
          - "Save these credentials securely!"

    - name: Save monitoring credentials
      copy:
        content: |
          Monitoring Stack Credentials
          ===========================
          
          Grafana:
          --------
          URL: https://{{ grafana_domain }}
          Username: admin
          Password: {{ grafana_password }}
          
          Prometheus:
          -----------
          URL: https://{{ prometheus_domain }}
          Username: admin
          Password: {{ prometheus_password_generated.stdout }}
          
          Alertmanager:
          -------------
          URL: https://{{ alertmanager_domain }}
          Username: admin
          Password: {{ alertmanager_password_generated.stdout }}
          
          Loki (Logging):
          ---------------
          URL: https://{{ loki_domain }}
          Username: admin
          Password: {{ loki_password_generated.stdout }}
          
          Security Features Enabled:
          - Basic authentication on Prometheus, Alertmanager, and Loki
          - Enhanced security headers (HSTS, XSS protection, frame options)
          - Rate limiting (50 req/s average, 100 burst) on all monitoring endpoints
          - IP whitelisting for private networks only
          - Multi-tenant Loki with authentication
          - Enhanced Grafana security headers and authentication
          - Security monitoring alerts and anomaly detection
          - Network segmentation with overlay networks
          - Resource limits and restart policies
          - TLS 1.2+ encryption with strong cipher suites
          - X-Robots-Tag to prevent search engine indexing
          
          Generated on: {{ ansible_date_time.iso8601 }}
        dest: /opt/docker/stacks/monitoring/credentials.txt
        mode: '0600'